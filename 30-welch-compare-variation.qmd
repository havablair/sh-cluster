# Welch ANOVA - compare variation explained

## Overview

This chapter is similar to 28 (compare variation demo), but here am using Welch ANOVA followed by calculation of epsilon squared as an effect size (which we can do because `{effectsize}` uses the F stats from the Welch's ANOVA to estimate epsilon squared.

The goal is to use selected soil health indicators from the CIG dataset to compare the amount of variation explained when grouping the data by geographic region (per the CIG design) vs. taxaonomy vs. soil health group (generated by k-means clustering).

This is meant to be a demonstration of how the soil health groups generated by k-means might be useful in helping to set benchmarks and expectations for soil health indicators measured on different types of soil.
The logic is that by reducing the within-group variation through stratification by group or region, we make it easier to detect **changes resulting from management differences**.

## Models

Response variables: soil health indicators (perhaps the NRCS tech note list?).
Should we use just 1 year of data to avoid pulling in year-to-year variability?
Could choose 2019, because this is the year for which we have PLFA data, and PLFA is on the NRCS list.

Variables from the NRCS Soil Health Tech Note recommended methods:

-   Aggregate stability
-   PMC
-   (skip - known weirdness in CIG data from different pHs/discussed with Nic). enzyme activities (BG, NAG, PASE) we have cellobiohydrolase data too, but skipping it b/c we have more missing data for this one (supply chain issues) and it's not on the NRCS list, which I'm using as my justification for choosing these ones
-   POXC
-   (skip - weird thing with RRV poor extraction in CIG data) ACE Protein
-   PLFA

```{r setup}

library(tidyverse)
library(glue)
library(ggbeeswarm)
library(lmerTest)
library(rstatix)
library(gt)

```

## Data

As part of the validation process for my k-means analysis, I determined the soil health group assigned to each CIG sampling area at the mapunit level (hillslope within management condition).

### Load data

```{r data}
#| message: false
#| warning: false

# this file created in "extract_raster_values_at_validation_points.R"
# it is at the "sample" level
cig_comps <- read_csv("data/cig_incl_components_table.csv") %>% 
  # for now, just using 2019 data so we avoid the year-to-year variability we
  # know is there, and b/c we have PLFA data for 2019 only
  filter(sample_id %in% c(1:243))


# this is for disambiguating which MUKEY should be assigned
# to each CIG val_unit_id (mapunit), because sometimes the
# GPS points landed in multiple mapunits
# the code that handles this is in "extract_raster_values_at_validation_points.R
cig_mukey_votes <- read_csv("data/cig_mukey_votes_for_validation.csv") 

# cluster assigned to each CIG point. this dataset is created in "prep_validation_data_for_pca_version.R"
# it is at the "validation unit" level (summarized to hillslope within management)
cig_clus <- read_csv("data/validation_data_pca_clusters_and_soil_props.csv") %>% 
  filter(str_detect(val_unit_id, "CV") |
           str_detect(val_unit_id, "SH") |
         str_detect(val_unit_id, "UD")) %>%
  mutate(region = str_extract(val_unit_id, "[:alpha:]{2}"),
         soil_group = glue("grp-{k_8}")) %>% 
  select(val_unit_id, soil_group, k_8, region)

# currently from csv saved by "heatmap_validation_counties.R", 
# but need to move this to a more logical place 
cig_mlras <- read_csv("data/cig_mlra_by_val_unit_id.csv") 

cig_val <- left_join(cig_clus, cig_mlras, by = "val_unit_id") %>%
  # need to fix this NA created by the join, it happened
  # because this RR4-CV site had a label change from A to B
  # during the harmonization I did to align soil textures
  mutate(
    MLRA_NAME = case_when(
      val_unit_id == "RR4-CV-B" ~ "Red River Valley of the North",
      TRUE ~ MLRA_NAME
    ),
    mlra_short = case_when(
      str_detect(MLRA_NAME, "Eastern Iowa") ~ "E IA MN Till",
      str_detect(MLRA_NAME, "Red River") ~ "Red River",
      str_detect(MLRA_NAME, "Rolling Till Prairie") ~ "Rol Till Pr",
      str_detect(MLRA_NAME, "Central Min") ~ "C MN Sandy",
      str_detect(MLRA_NAME, "Gray Drift") ~ "N MN Gray",
      str_detect(MLRA_NAME, "Central Iowa") ~ "C IA MN Till",
      TRUE ~ "Fix me"
    )
  )

# want all the CIG lab observations (not averaged to the plot level)
lab <- read_csv("../CIG/cig-main/cig_lab_data_all_20230301.csv") %>%
  mutate(val_unit_id = glue("{site}-{treatment}-{position}")) %>%
  select(
    sample_id,
    val_unit_id,
    region,
    position,
    corr_percent_stable_gr2mm,
    ugC_g_day,
    BG_activity,
    NAG_activity,
    P_activity,
    poxc_mg_kg,
    mean_protein_mg_g,
    mbc_ug_g_soil,
    mbn_ug_g_soil,
    total_living_microbial_biomass_plfa_ng_g,
    total_bacteria_plfa_ng_g,
    total_fungi_plfa_ng_g,
    total_bacteria_percent_of_tot_biomass,
    total_fungi_percent_of_tot_biomass
  ) %>% 
  filter(sample_id %in% c(1:243))

# missing data due to sample contamination in 2019 samples
# that were run for PLFA. Pulling MBN values from 2020
# for this validation site only after confirming that the values 
# are in a similar range for this soil type, hillslope position,
# and region
mbn_mw4_cva <-
  read_csv("../CIG/cig-main/cig_lab_data_all_20230301.csv") %>%
  mutate(val_unit_id = glue("{site}-{treatment}-{position}")) %>%
  filter(sample_id %in% c(474:476)) %>%
  pull(mbn_ug_g_soil) %>%
  mean(., na.rm = TRUE)



```

### Summarize to mapunit level

Recall that the lab data and the component data need to be summarized to the "mapunit" level.
This involves averaging the soil properties and determining the majority taxonomic classification for each MUKEY based on the included components (recall that most MUKEYs have just 1 contributing component, so we just need to account for those that have \>1 contributing component to determine, for each level of taxonomy I look at, what the majority assignment should be).

Starting with the taxonomy data:

```{r}
# how many unique mukeys are we working with?
(cig_mukeys <- cig_comps %>%
    pull(mukey) %>%
    unique() %>%
    length())

# Q: which mukeys have multiple components contributing data?
# A: 16 unique mukeys
cig_comps %>% 
  select(mukey, cokey, taxclname:taxpartsize) %>% 
  distinct() %>% 
  group_by(mukey) %>% 
  count() %>% 
  filter(n>1)

# goal: assign each mukey a representative suborder
# based on the suborders of the components within it.
# should get back object w/ length 37 (# of unique mukeys)
cig_comps %>% 
  select(mukey, cokey, comppct_r, taxsuborder) %>% 
  distinct() %>% 
  group_by(mukey, taxsuborder) %>% 
  summarise(tot_percent = sum(comppct_r), .groups = "drop") %>% 
  group_by(mukey) %>% 
  slice_max(tot_percent)


```

Function for determining representative taxonomic level .
Using similar code to the example with suborder above, this function allows me to summarize the representative taxonomic level (order, suborder, etc.) based on % area.

```{r}
# calculate representative taxonomy
calc_rep_tax <- function(tax_level, comp_df){
  
  comp_df %>% 
  select(mukey, cokey, comppct_r, {{tax_level}}) %>% 
  distinct() %>% 
  group_by(mukey, {{tax_level}}) %>% 
  summarise(tot_percent = sum(comppct_r), .groups = "drop") %>% 
  group_by(mukey) %>% 
  slice_max(tot_percent) %>% 
    select(-tot_percent)
  
}


order <- calc_rep_tax(taxorder, cig_comps)
suborder <- calc_rep_tax(taxsuborder, cig_comps)
grt_grp <- calc_rep_tax(taxgrtgroup, cig_comps)
sub_grp <- calc_rep_tax(taxsubgrp, cig_comps)
family <- calc_rep_tax(taxclname, cig_comps)

tax_joined <- list(order, suborder, grt_grp, sub_grp, family) %>% 
  purrr::reduce(., left_join, by = "mukey")

tax_val_key <- cig_comps %>% 
  select(val_unit_id, mukey) %>% 
  distinct()

```

Now time to summarize the lab data to the mapunit level, this is easier than the taxonomy because we can just take the average.
Recall that we are working with 2019 data only.

```{r}

lab_summary <- lab %>% 
  select(-sample_id) %>% 
  group_by(val_unit_id) %>% 
  summarise(across(where(is.numeric),
                   ~mean(.x, na.rm = TRUE)))
```

### Join taxonomic and lab info with validation dataset

Here, we create a dataset with one row for each validation unit in the CIG dataset.
It includes information about representative taxonomic classification at different levels (order, suborder, great group) and also representative values for the soil health indicators we want to analyze further below when comparing variance explained by different stratification options (region, taxonomy, k-means group).

```{r}


val_mukey <- left_join(cig_val, cig_mukey_votes, by = "val_unit_id") %>% 
  select(-c(n, max_vote))

val_mukey_lab <- left_join(val_mukey, lab_summary, by = "val_unit_id")

val_all <- left_join(val_mukey_lab, tax_joined, by = "mukey") %>%
 # on list from old key, this id no longer exists
   filter(val_unit_id != "RR4-CV-B") %>% 
  mutate(mbn_ug_g_soil = case_when(
    # dealing with missing data, see note at end of 
    # "load data" code block
    val_unit_id == "MW4-CV-A" ~ mbn_mw4_cva,
    TRUE ~ mbn_ug_g_soil
  ))


```

## Response variables - exploratory plots

```{r}

rvars <- c("corr_percent_stable_gr2mm",
               "ugC_g_day",
               "poxc_mg_kg",
               "mbc_ug_g_soil",
               "mbn_ug_g_soil", # include MBN?
               "total_living_microbial_biomass_plfa_ng_g",
               "total_bacteria_plfa_ng_g",
               "total_fungi_plfa_ng_g"
)


val_long <- val_all %>% 
  select(val_unit_id, all_of(rvars)) %>% 
  pivot_longer(-val_unit_id) %>% 
  mutate( name = case_when(
    name == "corr_percent_stable_gr2mm" ~ "agg_stab",
    name == "ugC_g_day" ~ "pmc_ugCgday",
    name == "total_living_microbial_biomass_plfa_ng_g" ~ "PLFA total",
    name == "total_bacteria_plfa_ng_g" ~ "PLFA bacteria",
    name == "total_fungi_plfa_ng_g" ~ "PLFA fungi",
    TRUE ~ name
    
  ))

val_long %>% 
  ggplot() + 
  geom_histogram(aes(value), bins = 20) +
  facet_wrap(vars(name), scales = "free") +
  ggtitle("Distribution (not transformed)")

val_all %>% 
  select(val_unit_id, contains("percent_of")) %>% 
  pivot_longer(-val_unit_id) %>% 
  ggplot() +
  geom_histogram(aes(value), bins = 20) + 
  facet_wrap(vars(name))

val_all %>% 
  select(val_unit_id, contains("percent_of")) %>% 
  pivot_longer(-val_unit_id) %>% 
  group_by(name) %>% 
  summarise(min = min(value), 
            max = max(value))
```

## Stratification options

We could stratify the CIG points based on several different levels of Soil Taxonomy.
How do the CIG sampling points break down in terms of number per cluster, and number per taxonomic level(s) (order, suborder, etc)?

For k-means clusters/groups: here we see that there is only 1 representative from group 4, so probably won't be able to use that group for any calculations.
But the others are workable.

For the different taxonomic levels, suborder seems workable, it has \>= 5 validation units in any given level.
I think order is too broad, and by the time we get to sub-group, we have two subgroups with just 1 validation unit each, so would have to drop those.

```{r}

val_all %>% 
  count(k_8)

val_all %>% 
  count(mlra_short)

val_all %>% 
  count(taxorder)

val_all %>% 
  count(taxsuborder) 

val_all %>% 
  count(taxgrtgroup)

val_all %>% 
  count(taxsubgrp)

val_all %>% count(taxclname)

xtabs(~region+taxorder, data = val_all)


```

```{r}
#| echo: false

suborder_gt <- val_all %>% 
  count(taxsuborder) %>% 
    gt() %>% 
    cols_label(taxsuborder = "Suborder")

mlra_gt <- val_all %>% 
  count(MLRA_NAME) %>% 
    gt() %>% 
    cols_label(MLRA_NAME = "Geographic/MLRA")

km_gt <- val_all %>% 
  count(k_8) %>% 
    gt() %>% 
    cols_label(k_8 = "K-means Group") %>% 
  tab_footnote(footnote = "Group 4 not included in tests",
               placement = "right")
    

gtsave(suborder_gt, "figs/suborder_counts.png")  

gtsave(mlra_gt, "figs/mlra_counts.png")

gtsave(km_gt, "figs/km_group_counts.png")
```

## Crosstabs w/ UD

Was originally thinking about whether we should include or exclude UD (undisturbed/unfarmed sites) because we know they are a major source of variance (they have much higher values across the board for all these indicators).

```{r}
xtabs(~soil_group + taxsuborder, data = val_all)

xtabs(~taxgrtgroup + soil_group, data = val_all)

xtabs(~mlra_short + soil_group, data = val_all)

```

## Crosstabs w/out UD

```{r}
val_farm <- val_all %>% 
  filter(!str_detect(val_unit_id, "UD"))

xtabs(~soil_group + region, data = val_farm)

xtabs(~soil_group + taxsuborder, data = val_farm)

xtabs(~taxgrtgroup + soil_group, data = val_farm)



```

## Plots

```{r}
#| warning: false

# keep only data points for soil regions where we have >1 validation area (need to drop group 4)
sub_dat <- val_all %>% 
  filter(k_8 %in% c(2, 3, 5:7))

# creating this so I can test difference between including/excluding the UD sites.
farmdat <- sub_dat %>% 
  filter(!str_detect(val_unit_id, "UD"))

sub_dat %>% 
  ggplot(aes(x = mlra_short, y = poxc_mg_kg)) + 
  geom_boxplot() +
  geom_quasirandom(aes(color = soil_group)) +
  theme_bw() +
  ggtitle("MLRA")

sub_dat %>% 
  ggplot(aes(x = soil_group, y = poxc_mg_kg)) +
  geom_boxplot() + 
  geom_quasirandom() +
  theme_bw() + 
  ggtitle("Cluster/Group")


sub_dat %>% 
  ggplot(aes(x = taxsuborder, y = poxc_mg_kg)) +
  geom_boxplot() + 
  geom_quasirandom(aes(color = soil_group)) +
  theme_bw() +
  ggtitle("Suborder")

sub_dat %>% 
  ggplot(aes(x = taxgrtgroup, y = poxc_mg_kg)) +
  geom_boxplot() + 
  geom_quasirandom(aes(color = soil_group)) +
  theme_bw() +
  ggtitle("Great Group") +
  theme(axis.text.x = element_text(angle = 15))


```

### Checking distributions

Transformations needed (based on inspecting the plots below):

-   None: aggregate stability, POXC
-   Log10: total biomass PLFA, total bacteria PLFA, total fungi PLFA, MBC, MBN, PMC

```{r}
#| echo: false

plot_transformations <- function(var,
                                 df,
                                 log10_adjust = 0,
                                 ln_adjust = 0,
                                 sqrt_adjust = 0,
                                 nbins = 30) {
  trans_df <- df %>%
    select(val_unit_id, {{var}}) %>%
    mutate(
      log10_trans = log10({{var}} + log10_adjust),
      ln_trans = log({{var}} + ln_adjust),
      sqrt_trans = sqrt({{var}} + sqrt_adjust)) %>%
  pivot_longer(cols = -c(val_unit_id))
  
  var_string <- deparse(substitute(var))


  trans_df %>%
    ggplot(aes(x = value)) +
    geom_histogram(bins = nbins) +
    facet_wrap(vars(name), scales = "free") +
    theme_bw() +
    ggtitle(glue("{var_string}"))

}
```

#### Aggregate stability

```{r}

plot_transformations(var = corr_percent_stable_gr2mm,
                     df = val_all,
                     nbins = 15)

```

#### PLFA Indicators

```{r}

plot_transformations(var = total_living_microbial_biomass_plfa_ng_g,
                     df = val_all,
                     nbins = 15)

plot_transformations(var = total_bacteria_plfa_ng_g,
                     df = val_all,
                     nbins = 15)

plot_transformations(var = total_fungi_plfa_ng_g,
                     df = val_all,
                     nbins = 15)

```

#### Microbial biomass C & N (CFE)

```{r}

plot_transformations(var = mbc_ug_g_soil,
                     df = val_all,
                     nbins = 15)

plot_transformations(var = mbn_ug_g_soil,
                     df = val_all,
                     nbins = 15)

```

#### POXC

```{r}
plot_transformations(var = poxc_mg_kg,
                     df = val_all,
                     nbins = 15)
```

#### PMC

```{r}
plot_transformations(var = ugC_g_day,
                     df = val_all,
                     nbins = 10)
```

## Function to plot model checks

```{r}

check_plots_anova <- function(soil_var, strat, df, log_trans) {
  
  dat_no_na <- df %>%
    select(val_unit_id,
           all_of(strat),
           all_of(soil_var)) %>%
    drop_na(all_of(soil_var))
  
  # checking if any clusters are represented by 1 or less data points. Want to drop these cuz can't calc variance with only 1

  n_obs_per_group <- dat_no_na %>%
    count(.data[[strat]])
  
  single_obs_groups <- n_obs_per_group %>%
    filter(n <= 1) %>%
    pull(.data[[strat]])
  
  if (length(single_obs_groups) == 0) {
    dat_subset <- dat_no_na
    
  } else{
    dat_subset <- dat_no_na %>%
      filter(!(.data[[strat]] %in% single_obs_groups))
    
  }
  
  if (log_trans){
    
    f <- paste0("log(", soil_var, ") ~ ", strat)
    
  }else{
    
    f <- paste0(soil_var, " ~ ", strat)
    
  }
  
  mod <- lm(formula = f,
            data = dat_subset)
  
  check_plots <- performance::check_model(mod, check = c("normality", "homogeneity", "linearity"))  
  
  return(list(f_used = f,
              plots = check_plots))
  
}
```

## Models to check

Working with these independent variables (stratification options):

1.  soil_group (k-means);
2.  mlra_short
3.  taxsuborder
4.  taxgrtgroup

```{r}

(dep_vars <- c("corr_percent_stable_gr2mm",
               "ugC_g_day",
               "poxc_mg_kg",
               "mbc_ug_g_soil",
               "mbn_ug_g_soil", # include MBN?
               "total_living_microbial_biomass_plfa_ng_g",
               "total_bacteria_plfa_ng_g",
               "total_fungi_plfa_ng_g"
))

# determined by inspecting histograms above w/ different
# transformation options
log_trans <- c(FALSE, 
               TRUE, 
               FALSE, 
               TRUE,
               TRUE,
               TRUE,
               TRUE,
               TRUE)

```

### K-means soil groups

```{r}

map2(
  .x = dep_vars,
  .y = log_trans,
  .f = ~ check_plots_anova(
    soil_var = .x,
    log_trans = .y,
    strat = "soil_group",
    df = val_all
  )
)

```

### Region

```{r}
map2(
  .x = dep_vars,
  .y = log_trans,
  .f = ~ check_plots_anova(
    soil_var = .x,
    log_trans = .y,
    strat = "region",
    df = val_all
  )
)
```

### Suborder

```{r}
map2(
  .x = dep_vars,
  .y = log_trans,
  .f = ~ check_plots_anova(
    soil_var = .x,
    log_trans = .y,
    strat = "taxsuborder",
    df = val_all
  )
)
```

## Effect sizes for variance explained

**Add updated references** from reading notes on 2023-03-16 re: calculating effect sizes from F statistics (which is what `{effectsize}` is doing for us behind the scenes when we pass the Welch's ANOVA results to `epsilon_squared()`

I was originally planning on calculating eta-squared as my effect size, using either: [`effectsize::eta_squared()`](https://easystats.github.io/effectsize/reference/eta_squared.html) for ANOVA or [`effectsize::rank_eta_squared()`](https://easystats.github.io/effectsize/reference/rank_epsilon_squared.html)`.` But in reading the [documentation](https://easystats.github.io/effectsize/reference/eta_squared.html) for `eta_squared()` from `{effectsize}`, I learned that there are other, less biased options for calculating this value: omega-squared and epsilon-squared.

I found a very helpful, recent reference, Iacobucci et al., (2023), that explains the differences between eta, epsilon, and omega when used as effect sizes of variance explained.
See their paper for the details, but the easiest way to think about it is that using epsilon-squared or omega-squared is essentially like reporting an adjusted R2 value instead of a regular R2 value.
It's better to use epsilon squared because the equation accounts for small sample size, which is relevant in our case.

Below is an example with MBC, this is just me figuring out what the different functions outputs look like, and how NAs are handled.

### Example

```{r}

## welch's ANOVA - MBC by soil_group (k-means)

test_welch <- oneway.test(data = sub_dat,
            formula = mbc_ug_g_soil ~ soil_group,
           var.equal = FALSE,
            na.action = "na.omit")

test_welch

effectsize::epsilon_squared(test_welch, partial = FALSE)

```

Below I test out Welch's ANOVA followed by calculation of epsilon squared.
This works, and after reading more from the `{effectsize}` documentation [here](https://easystats.github.io/effectsize/reference/F_to_eta2.html) I think I understand how.
I can pass the result from `oneway.test(var.equal = FALSE)` to `effectsize::epsilon_squared()` and there is an intermediate step performed where the F statistic from `oneway.test` is converted to the effect size (could be partial eta-squared, omega-squared, or epsilon-squared)

### Setup dataframe

Transformations needed:

-   None: aggregate stability, POXC
-   Log10: total biomass PLFA, total bacteria PLFA, total fungi PLFA, MBC, MBN, PMC

```{r}
strat_opts <- c("soil_group", "mlra_short", "taxsuborder",
                "taxgrtgroup")

mod_frame <- tidyr::crossing(dep_vars, strat_opts)

# apply the transformations I decided on above after looking at 
# "checking distributions" plots
dat_trans <- sub_dat %>% 
  mutate(across(.cols = c(total_living_microbial_biomass_plfa_ng_g,
                          total_bacteria_plfa_ng_g,
                          total_fungi_plfa_ng_g,
                          mbc_ug_g_soil,
                          mbn_ug_g_soil,
                          ugC_g_day), 
                .fns = log10
                ))
# creating a farm dataset so I can compare results 
# for including vs. excluding UD sites
dat_farm <- dat_trans %>% 
  filter(!str_detect(val_unit_id, "UD"))
```

### Function run ANOVA & calculate epsilon squared

```{r}


calc_welch_eps_sq <- function(soil_var,
                              strat,
                              df = dat_trans) {
  
  my_formula <- as.formula(paste0(soil_var, " ~ ", strat))
  
  
  mod_obj <- oneway.test(
    formula = my_formula,
    data = df,
    var.equal = FALSE,
    na.action = "na.omit"
  )

    eps_sq <- effectsize::epsilon_squared(model = mod_obj,
                        # partial FALSE b/c one-way test
                        # we don't have other vars to
                        # break the variance down by
                        partial = FALSE)

  return(eps_sq)

}


```

### Calculate epsilon squared

```{r}
#| message: false
#| warning: false

# quieted the message "`var.equal = FALSE` - effect size is an approximation.", it's a reminder that this effect size is an apporximation because we are estimating it based on the f statistic from our Welch's ANOVA

eps_inputs <- mod_frame %>% 
  rename(strat = strat_opts, 
         soil_var = dep_vars) %>% 
  select(soil_var, strat) 

# returns bunch of reminders about how the eff size is 
# an approximation (b/c we are calculating it from F stat,
# not directly from SS)
eps_results <- eps_inputs %>%
  mutate(eps_results = map2(
    .x = soil_var,
    .y = strat,
    .f = ~ calc_welch_eps_sq(
      soil_var = .x,
      strat = .y,
      df = dat_trans
    )
  ))


eps_farm <- eps_inputs %>%
  mutate(eps_results = map2(
    .x = soil_var,
    .y = strat,
    .f = ~ calc_welch_eps_sq(
      soil_var = .x,
      strat = .y,
      df = dat_farm
    )
  ))


```

### Clean up data

```{r}


eps_long <- eps_results %>% 
  unnest(eps_results) %>% 
  rename(epsilon_sq = Epsilon2)

farm_long <- eps_farm %>% 
  unnest(eps_results) %>% 
  rename(epsilon_sq = Epsilon2)

# eps_wide <- eps_long %>% 
#   pivot_wider(values_from = c("epsilon_sq", "type"), 
#               names_from = "strat")
```

### Table of variance explained

```{r}

eps_long %>% 
  filter(strat != "taxgrtgroup") %>% 
  mutate(soil_var = case_when(
    str_detect(soil_var, "stable") ~ "Agg Stab",
    str_detect(soil_var, "mbc") ~ "MBC",
    str_detect(soil_var, "mbn") ~ "MBN",
    str_detect(soil_var, "poxc") ~ "POXC",
    str_detect(soil_var, "total_bact") ~ "Bact PLFA",
    str_detect(soil_var, "total_fungi") ~ "Fungi PLFA",
    str_detect(soil_var, "total_living") ~ "Total PLFA",
    str_detect(soil_var, "ugC") ~ "PMC",
  )) %>% 
  select(soil_var, strat, epsilon_sq) %>% 
  pivot_wider(names_from = "strat",
              values_from = "epsilon_sq") %>% 
  mutate(across(where(is.numeric), ~round(.x, digits = 2)))

  
  

```

### Plots of variance explained

```{r}
all_pts_labelled <- eps_long %>% 
  filter(strat != "taxgrtgroup") %>% 
  mutate(soil_var = case_when(
    soil_var == "mbc_ug_g_soil" ~ "MBC",
    soil_var == "mbn_ug_g_soil" ~ "MBN", 
    soil_var == "corr_percent_stable_gr2mm" ~ "Aggregate Stab.",
    soil_var == "poxc_mg_kg" ~ "POXC", 
    soil_var == "total_bacteria_plfa_ng_g" ~ "Bacteria PLFA",
    soil_var == "total_fungi_plfa_ng_g" ~ "Fungi PLFA",
    soil_var == "total_living_microbial_biomass_plfa_ng_g" ~ "Total Biomass PLFA", 
    soil_var == "poxc_mg_kg" ~ "POXC",
    soil_var == "ugC_g_day" ~ "PMC"
  ),
  strat = case_when(
    strat == "mlra_short" ~ "MLRA",
    strat == "soil_group" ~ "KM CLUSTER",
    strat == "taxsuborder" ~ "SUBORDER"
  )) %>%
  group_by(soil_var) %>%
  mutate(max_epsilon = max(epsilon_sq),
         top_strat = case_when(
           epsilon_sq == max_epsilon ~ "Y",
           TRUE ~ "N"
         ), 
  # round for nice labels 
         epsilon_sq_lab = round(epsilon_sq, digits = 2))

```

```{r}

# saving in case I want to compare farm (no UD) vs. w/ UD results

farm_labelled <- farm_long %>%
  filter(strat != "taxgrtgroup") %>%
  mutate(soil_var = case_when(
    soil_var == "mbc_ug_g_soil" ~ "MBC",
    soil_var == "mbn_ug_g_soil" ~ "MBN",
    soil_var == "corr_percent_stable_gr2mm" ~ "Aggregate Stab.",
    soil_var == "poxc_mg_kg" ~ "POXC",
    soil_var == "total_bacteria_plfa_ng_g" ~ "Bacteria PLFA",
    soil_var == "total_fungi_plfa_ng_g" ~ "Fungi PLFA",
    soil_var == "total_living_microbial_biomass_plfa_ng_g" ~ "Total Biomass PLFA",
    soil_var == "poxc_mg_kg" ~ "POXC",
    soil_var == "ugC_g_day" ~ "PMC"
  ),
  strat = case_when(
    strat == "mlra_short" ~ "MLRA",
    strat == "soil_group" ~ "KM CLUSTER",
    strat == "taxsuborder" ~ "SUBORDER"
  )) %>%
  group_by(soil_var) %>%
  mutate(max_epsilon = max(epsilon_sq),
         top_strat = case_when(
           epsilon_sq == max_epsilon ~ "Y",
           TRUE ~ "N"
         ), 
  # round for nice labels 
         epsilon_sq_lab = round(epsilon_sq, digits = 2))

```

## (with UD) variance explained plot

```{r}

plot_var_order <-
  c(
    "POXC",
  #  "Total Biomass PLFA",
    "Bacteria PLFA",
    "MBC",
    "MBN",
    "Fungi PLFA",
    "Aggregate Stab.",
    "PMC"
  )


eps_bar_plot <- all_pts_labelled %>%
  filter(soil_var != "Total Biomass PLFA") %>% 
  ggplot() +
  geom_col(aes(x = soil_var, y = epsilon_sq_lab, fill = strat),
           position = position_dodge(),
           width = 0.7, 
           color = "black") +
  # geom_text(aes(x = 8.25, y = 0.85, label = "A."), size = 3) +
  #   geom_text(aes(x = 6.25, y = 0.85, label = "B."), size = 3) +
  #   geom_text(aes(x = 4.25, y = 0.85, label = "C."), size = 3) +
  #   geom_text(aes(x = 1.25, y = 0.85, label = "D."), size = 3) +
  scale_x_discrete(limits = rev(plot_var_order)) +
  scale_y_continuous(breaks = seq(0, 0.7, 0.1), limits = c(0, 0.7)) +
#   geom_vline(aes(xintercept = 1.5)) +
#   geom_vline(aes(xintercept = 4.5)) +
#   geom_vline(aes(xintercept = 6.5)) +
  coord_cartesian(xlim = c(0, 0.7),
                  clip = 'off') +
  coord_flip() +
  theme_bw() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 1),
    legend.text = element_text(size = 8),
    legend.justification = c(1, 1)
  ) +
  xlab("") +
  ylab("Epsilon Squared") +
  #labs(caption = "With undisturbed (Welch's ANOVA)") +
  scale_fill_manual(values = c("#1b9e77", "#d95f02", "#7570b3")) +
  guides(fill = guide_legend(title = "Grouping Method")) 

ggsave("figs/epsilon_sq_barplot_ud.png", plot = eps_bar_plot, 
       width = 5, height = 5, units = "in")
```

## (No UD) variance explained table & plot

```{r}

farm_long %>% 
  filter(strat != "taxgrtgroup") %>% 
  mutate(soil_var = case_when(
    str_detect(soil_var, "stable") ~ "Agg Stab",
    str_detect(soil_var, "mbc") ~ "MBC",
    str_detect(soil_var, "mbn") ~ "MBN",
    str_detect(soil_var, "poxc") ~ "POXC",
    str_detect(soil_var, "total_bact") ~ "Bact PLFA",
    str_detect(soil_var, "total_fungi") ~ "Fungi PLFA",
    str_detect(soil_var, "total_living") ~ "Total PLFA",
    str_detect(soil_var, "ugC") ~ "PMC",
  )) %>% 
  select(soil_var, strat, epsilon_sq) %>% 
  pivot_wider(names_from = "strat",
              values_from = "epsilon_sq") %>% 
  mutate(across(where(is.numeric), ~round(.x, digits = 2)))

```

```{r}

# decided to use the same order as the above plot that also includes the UD data, to make comparison between them easier

# f_plot_var_order <- c("POXC", "Total Biomass PLFA","Aggregate Stab.", "Bacteria PLFA", "MBC", "MBN", "Fungi PLFA", "PMC")


farm_bar_plot <- farm_labelled %>%
  filter(soil_var != "Total Biomass PLFA") %>% 
  ggplot() +
  geom_col(aes(x = soil_var, y = epsilon_sq_lab, fill = strat),
           position = position_dodge(),
           width = 0.7,
           color = "black") +
  # geom_text(aes(x = 1, y = 0.9, label = "D."), size = 3) +
  # geom_text(aes(x = 3, y = 0.9, label = "C."), size = 3) +
  # geom_text(aes(x = 7.5, y = 0.9, label = "A."), size = 3) +
  #   geom_text(aes(x = 5.5, y = 0.9, label = "B."), size = 3) +
  scale_x_discrete(limits = rev(plot_var_order)) + 
  scale_y_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1.05)) +
 # geom_vline(aes(xintercept = 1.5)) +
 #  geom_vline(aes(xintercept = 4.5)) +
 #  geom_vline(aes(xintercept = 6.5)) +
  coord_flip() +
  theme_bw() +
theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 1),
    legend.text = element_text(size = 8),
    legend.justification = c(1, 1)
  ) +
  xlab("") +
  ylab("Epsilon Squared") +
  # labs(caption = "Just farm data/no undisturbed (Welch's ANOVA)") +
  scale_fill_manual(values = c("#1b9e77", "#d95f02", "#7570b3")) +
  guides(fill = guide_legend(title = "Grouping Method"))

ggsave(
  "figs/epsilon_sq_barplot_farms.png",
  plot = farm_bar_plot,
  width = 5,
  height = 5,
  units = "in"
)
```

## What is going on with PMC?

PMC returns 0% variance explained for all three stratification options: K-means, Region, and Taxonomic sub-group.
Is this really correct?
Let's double check below with the region stratification to make sure there isn't something weird with the data.

```{r}

lm_pmc <- lm(ugC_g_day ~ region, data = sub_dat, na.action = "na.omit")

aov_pmc <- car::Anova(lm_pmc, type = 2)

# big residuals number... that explains it
aov_pmc

effectsize::epsilon_squared(aov_pmc, partial = FALSE)

# what about eta-squared?
effectsize::eta_squared(aov_pmc, partial = FALSE)

# what if we drop the UD sites?

farmdat <- sub_dat %>% filter(!str_detect(val_unit_id, "UD"))

lm_farm <- lm(ugC_g_day ~ region, data = farmdat, na.action = "na.omit")

aov_farm <- car::Anova(lm_farm, type = 2)

# big residuals number... that explains it
aov_farm

effectsize::epsilon_squared(aov_farm, partial = FALSE)

# what about eta-squared?
effectsize::eta_squared(aov_farm, partial = FALSE)

```

## ANOVA models POXC

Trying this after reading Mourtzinis et al., 2020 about stratifying producer fields to better explain soybean yield variability

```{r}
#| eval: false 


# using poxc as example 
# check for missing values
nrow(sub_dat %>% filter(is.na(poxc_mg_kg)))

# summarise to mapunit level (val_unit_ids)
poxc_test <- sub_dat %>% 
  filter(!is.na(poxc_mg_kg)) %>% 
  group_by(val_unit_id, region, k_8) %>% 
  summarise(mean_poxc = mean(poxc_mg_kg),
            .groups = "drop") %>% 
  mutate(k_8 = glue("cl_{k_8}"))

reglm <- lm(mean_poxc ~ region, data = poxc_test)
#regposlm <- lm(mean_poxc ~ region*position, data = poxc_test)
clustlm <- lm(mean_poxc ~ k_8, data = poxc_test)

performance::check_model(reglm, check = c("normality", "linearity", "homogeneity", "outliers"))

anova_reg <- car::Anova(reglm) %>% broom::tidy() %>% column_to_rownames("term")

# anova_regpos <- car::Anova(regposlm) %>% broom::tidy() %>% column_to_rownames("term")
  
anova_clust <- car::Anova(clustlm) %>% broom::tidy() %>% 
  column_to_rownames("term")

# what percentage of variation is explained by the "region" term
# vs. the "cluster" term vs. the region and cluster terms (and their interaction?)

ss_reg <- anova_reg['region', 'sumsq']/sum(anova_reg['sumsq'])*100

# ss_regpos <- (anova_regpos['region', 'sumsq'] + 
#     anova_regpos['position', 'sumsq'] + 
#     anova_regpos['region:position', 'sumsq'] ) /sum(anova_reg['sumsq'])*100

ss_clust <- anova_clust['k_8', 'sumsq']/sum(anova_clust['sumsq'])*100


ss_reg
ss_regpos
ss_clust
```

## ANOVA models MBC

```{r}
#| eval: false


# using poxc as example 
# check for missing values
nrow(sub_dat %>% filter(is.na(mbc_ug_g_soil)))

mbc_test <- sub_dat %>% 
  filter(!is.na(mbc_ug_g_soil)) %>% 
  group_by(val_unit_id, region, k_8, position) %>% 
  summarise(mean_mbc = mean(mbc_ug_g_soil),
            .groups = "drop") %>% 
  mutate(k_8 = glue("cl_{k_8}"))

reglm <- lm(mean_mbc ~ region, data = mbc_test)
regposlm <- lm(mean_mbc ~ region*position, data = mbc_test)
clustlm <- lm(mean_mbc ~ k_8, data = mbc_test)

anova_reg <- car::Anova(reglm) %>% broom::tidy() %>% column_to_rownames("term")

anova_regpos <- car::Anova(regposlm) %>% broom::tidy() %>% column_to_rownames("term")
  
anova_clust <- car::Anova(clustlm) %>% broom::tidy() %>% 
  column_to_rownames("term")

# what percentage of variation is explained by the "region" term
# vs. the "cluster" term vs. the region and cluster terms (and their interaction?)

ss_reg <- anova_reg['region', 'sumsq']/sum(anova_reg['sumsq'])*100

ss_regpos <- (anova_regpos['region', 'sumsq'] + 
    anova_regpos['position', 'sumsq'] + 
    anova_regpos['region:position', 'sumsq'] ) /sum(anova_reg['sumsq'])*100

ss_clust <- anova_clust['k_8', 'sumsq']/sum(anova_clust['sumsq'])*100


ss_reg
ss_regpos
ss_clust
```

## (Old) Calculate coefficient of variation

Old stuff here but wanted to keep track of the cvequality package link in case it's useful at some other point...
My idea was to use coefficient of variation (%) to compare the spread of the points when grouped by geographic region vs. soil group.
I found a helpful R package to do this (which includes stats citations): [`{cvequality}`](https://cran.r-project.org/web/packages/cvequality/vignettes/how_to_test_CVs.html)
