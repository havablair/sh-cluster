{
  "hash": "78ccd3ca0b16259564ac02f76a607ea8",
  "result": {
    "markdown": "# Sample validation points\n\nNow that we have our clustering candidates from the k-means models saved as raster files, to validate the models we need to sample the rasters at the locations where the soil samples were collected.\nThis will tell us which \"region\" or cluster the sample falls into, based on its position on the map.\nWe will do this for each raster we generated (different \\# of clusters).\n\nAfter we have this information for our validation points, we can compare the expected means and ranges of soil properties from the SSURGO data (by summarizing our model results, probably spatially weighted) with the soil property values measured at the validation points.\n\n## Validation datasets\n\nThere are 3 main validation datasets that I currently have access to:\n\n-   NRCS SHI project (Jess). Validation completed by Joe Brennan, saved in data \\> validation data \\> NCRS-SHI \\> shi_site_allvar_validation_20221116.csv\n-   CIG field data\n-   NCSS data from KSSL. I completed the data cleaning and merging process with the script `unqip_merge_ncss_data.R`. The dataset (all props averaged to 0-20cm) is saved in data \\> validation data \\> NCSS-KSSL \\> validation_ncss_kssl_0-20cm_aggr.csv\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(terra)\n\n# points to validate\nncss_dat <- read_csv(\"data/validation_data/NCSS-KSSL/validation_ncss_kssl_0-20cm_aggr.csv\")\n\n# ended up making these matrices so I can add ids as an \"attribute\" (atts) in the vect function \nncss_pts <- ncss_dat %>% \n  select(longitude_decimal_degrees, latitude_decimal_degrees) %>% \n  rename(lon = longitude_decimal_degrees,\n         lat = latitude_decimal_degrees) %>% \n  as.matrix()\n\ncig_dat <- read_csv(\"../CIG/cig-main/cig_lab_data_all_20221129.csv\")\n\ncig_pts <- cig_dat %>% \n  select(lon, lat) %>% \n  as.matrix()\n\n# I am using these dfs to see if setting sample ID as an attribute in the\n# SpatVector below will allow me to identify the points more readily after\n# extract()\ncig_ids <- data.frame(sample_id = cig_dat$sample_id,\n                      row.names = NULL)\n\nncss_ids <- data.frame(pedon_key = ncss_dat$pedon_key)\n```\n:::\n\n\n## Reproject points to NAD 83 Albers\n\nMy rasters are in NAD 1983 Albers projection (EPSG: 5070).\nMy points are in WGS 84 (EPSG: 4326, they are lon/lat).\nI need to reproject the points before I extract the raster values.\nThis involves two steps:\n\n-   Turn my 2-column dataframes (lon, lat) into SpatVector objects\n-   Reproject the SpatVector objects to the correction CRS\n\nFrom the `{terra}` documentation: \"You can use a data.frame to make a SpatVector of points; or a\"geom\" matrix to make a SpatVector of any supported geometry (see examples and `geom`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# turn the CIG and NCSS points dfs to SpatVectors\ncig_spat <- vect(x = cig_pts,\n     type = \"points\",\n     # EPSG:4326 is WGS84 long/lat\n     crs = \"epsg:4326\",\n     atts = cig_ids\n     )\n\nncss_spat <- vect(x = ncss_pts,\n                  type = \"points\",\n                  # EPSG:4326 is WGS84 long/lat\n                  crs = \"epsg:4326\",\n                  atts = ncss_ids)\n\n# reproject the CIG and NCSS points to NAD 83 (EPSG 5070)\ncig_reproj <- project(x = cig_spat,\n                      y = \"epsg:5070\")\n\ncig_reproj\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n class       : SpatVector \n geometry    : points \n dimensions  : 486, 1  (geometries, attributes)\n extent      : -83294.72, 263752.5, 2296221, 2843822  (xmin, xmax, ymin, ymax)\n coord. ref. : NAD83 / Conus Albers (EPSG:5070) \n names       : sample_id\n type        :     <num>\n values      :         1\n                       2\n                       3\n```\n:::\n\n```{.r .cell-code}\nncss_reproj <- project(x = ncss_spat,\n                    y = \"epsg:5070\")\n\nncss_reproj\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n class       : SpatVector \n geometry    : points \n dimensions  : 49, 1  (geometries, attributes)\n extent      : -56529.96, 395663.8, 2374854, 2848762  (xmin, xmax, ymin, ymax)\n coord. ref. : NAD83 / Conus Albers (EPSG:5070) \n names       : pedon_key\n type        :     <chr>\n values      :   02N0123\n                 02N0796\n                 02N0797\n```\n:::\n:::\n\n\n## Sample Rasters (Extract value)\n\nNeed to review relevant function/s from `{terra}` for doing the raster sampling.\nOtherwise I know how to do it already in QGIS.\n\nLooks like I want the `extract()` function.\n\"Sample\" has a different meaning in `{terra}`, (taking a spatial sample / regular sample)\n\nImportant arguments:\n\n-   `x` is the SpatRaster\n-   `y` (in my case) is a SpatVector, re-projected above\n-   `method` should be \"simple\", because I want the value of the cell the point falls into\n-   `xy` set to TRUE (return coordinates with results)\n-   `ID` set to TRUE (return IDs, record numbers, of input SpatVector y)\n\n### An example\n\nOK, got this working after some silly troubleshooting with attributes and CRS (had the wrong EPSG code for NAD 1983 Albers to start out).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# start with the k=2 model\ntest_rast <- rast(\"E:/big-files-backup/ch03-sh-groups/clust2_allvar.tif\")\n\next_df <- extract(x = test_rast,\n        y = cig_reproj,\n        method = \"simple\",\n        xy = TRUE,\n        ID = TRUE)  \n\n# also try it with the NCSS points, just to see:\nextract(x = test_rast,\n        y = ncss_reproj,\n        method = \"simple\", \n        xy = TRUE,\n        ID = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"ID\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Reclass_tif1\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"x\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"1\",\"3\":\"-20260\",\"4\":\"2746870\"},{\"1\":\"2\",\"2\":\"NA\",\"3\":\"242690\",\"4\":\"2707470\"},{\"1\":\"3\",\"2\":\"NA\",\"3\":\"231340\",\"4\":\"2702890\"},{\"1\":\"4\",\"2\":\"NA\",\"3\":\"231340\",\"4\":\"2702890\"},{\"1\":\"5\",\"2\":\"NA\",\"3\":\"235900\",\"4\":\"2702910\"},{\"1\":\"6\",\"2\":\"NA\",\"3\":\"237150\",\"4\":\"2702800\"},{\"1\":\"7\",\"2\":\"NA\",\"3\":\"223880\",\"4\":\"2744130\"},{\"1\":\"8\",\"2\":\"NA\",\"3\":\"249120\",\"4\":\"2716560\"},{\"1\":\"9\",\"2\":\"NA\",\"3\":\"262000\",\"4\":\"2658110\"},{\"1\":\"10\",\"2\":\"NA\",\"3\":\"296260\",\"4\":\"2684040\"},{\"1\":\"11\",\"2\":\"2\",\"3\":\"135770\",\"4\":\"2374850\"},{\"1\":\"12\",\"2\":\"2\",\"3\":\"135460\",\"4\":\"2374930\"},{\"1\":\"13\",\"2\":\"2\",\"3\":\"134180\",\"4\":\"2375080\"},{\"1\":\"14\",\"2\":\"2\",\"3\":\"129390\",\"4\":\"2445610\"},{\"1\":\"15\",\"2\":\"2\",\"3\":\"132460\",\"4\":\"2447510\"},{\"1\":\"16\",\"2\":\"NA\",\"3\":\"NaN\",\"4\":\"NaN\"},{\"1\":\"17\",\"2\":\"NA\",\"3\":\"NaN\",\"4\":\"NaN\"},{\"1\":\"18\",\"2\":\"NA\",\"3\":\"NaN\",\"4\":\"NaN\"},{\"1\":\"19\",\"2\":\"NA\",\"3\":\"320880\",\"4\":\"2751490\"},{\"1\":\"20\",\"2\":\"NA\",\"3\":\"330190\",\"4\":\"2748880\"},{\"1\":\"21\",\"2\":\"NA\",\"3\":\"337840\",\"4\":\"2748010\"},{\"1\":\"22\",\"2\":\"NA\",\"3\":\"348680\",\"4\":\"2755000\"},{\"1\":\"23\",\"2\":\"NA\",\"3\":\"356150\",\"4\":\"2749630\"},{\"1\":\"24\",\"2\":\"NA\",\"3\":\"365100\",\"4\":\"2747470\"},{\"1\":\"25\",\"2\":\"NA\",\"3\":\"372950\",\"4\":\"2741330\"},{\"1\":\"26\",\"2\":\"NA\",\"3\":\"314630\",\"4\":\"2749410\"},{\"1\":\"27\",\"2\":\"1\",\"3\":\"-45070\",\"4\":\"2846080\"},{\"1\":\"28\",\"2\":\"2\",\"3\":\"-56530\",\"4\":\"2842470\"},{\"1\":\"29\",\"2\":\"0\",\"3\":\"152830\",\"4\":\"2634470\"},{\"1\":\"30\",\"2\":\"0\",\"3\":\"152840\",\"4\":\"2634520\"},{\"1\":\"31\",\"2\":\"0\",\"3\":\"132330\",\"4\":\"2600780\"},{\"1\":\"32\",\"2\":\"0\",\"3\":\"132350\",\"4\":\"2600970\"},{\"1\":\"33\",\"2\":\"2\",\"3\":\"134530\",\"4\":\"2415400\"},{\"1\":\"34\",\"2\":\"2\",\"3\":\"134420\",\"4\":\"2416000\"},{\"1\":\"35\",\"2\":\"2\",\"3\":\"134140\",\"4\":\"2416460\"},{\"1\":\"36\",\"2\":\"1\",\"3\":\"-33870\",\"4\":\"2770710\"},{\"1\":\"37\",\"2\":\"1\",\"3\":\"-33620\",\"4\":\"2770610\"},{\"1\":\"38\",\"2\":\"2\",\"3\":\"-34290\",\"4\":\"2771610\"},{\"1\":\"39\",\"2\":\"2\",\"3\":\"-16470\",\"4\":\"2848580\"},{\"1\":\"40\",\"2\":\"2\",\"3\":\"-3970\",\"4\":\"2848760\"},{\"1\":\"41\",\"2\":\"2\",\"3\":\"-1270\",\"4\":\"2848640\"},{\"1\":\"42\",\"2\":\"2\",\"3\":\"1550\",\"4\":\"2666580\"},{\"1\":\"43\",\"2\":\"2\",\"3\":\"1550\",\"4\":\"2666580\"},{\"1\":\"44\",\"2\":\"2\",\"3\":\"1580\",\"4\":\"2666580\"},{\"1\":\"45\",\"2\":\"0\",\"3\":\"1620\",\"4\":\"2666510\"},{\"1\":\"46\",\"2\":\"0\",\"3\":\"1630\",\"4\":\"2666520\"},{\"1\":\"47\",\"2\":\"2\",\"3\":\"1650\",\"4\":\"2666530\"},{\"1\":\"48\",\"2\":\"2\",\"3\":\"1660\",\"4\":\"2666520\"},{\"1\":\"49\",\"2\":\"2\",\"3\":\"1740\",\"4\":\"2666510\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n### Brainstorm process to iterate with \"extract\"\n\nAgain, thinking about how I want to be able to set up the steps of this process in a `{targets}` pipeline, the meat of this process of extracting raster values will be done in a separate R script.\nHere I am thinking through how I would structure that.\n\n-   Setup: Like above, load the locations and sample IDs for the points I want to use in my validation. Combine the CIG and NCSS points into a single dataframe. Then do Data.frame \\> matrix \\> spat vector w/ ID attribute\n-   Write a custom function that will:\n    -   Load a raster for a given value of `k`\n\n    -   Extract raster values at our target points -\\> this is a dataframe.\n        Make sure the raster value column has an informative name that includes the `k` value so we can distinguish it\n\n    -   Remove the raster (it's big, we dont need it any more)\n\n    -   Return the dataframe\n-   Use map to run the custom function above, iterating over values of `k` from 2-20 and column-binding the results, so we end up with a dataframe that has rows = validation points, and columns = raster values for different `k` cluster sizes\n\n### Finished raster extract process (CIG, NCSS)\n\nThe script `R/extract_raster_values_at_validation_points.R` implements the process described above.\nAt the end of that script, I save a CSV file in wide format with the CIG and NCSS_KSSl validation data `cig_ncss-kssl_allvar_validation_20221230.csv`.\n\nThe next step is to combine the validation data, which identifies the cluster assignments, with the soil property data.\nI will do this in the next chapter.\n\n## Number points per dataset & soil property\n\nIn the manuscript, I'd like to report how many points came from each of our three datasets.\nHere is some code to determine this.\nThe best place to start is the dataset that I prepped for pairwise comparisons using `R/prep_validation_data_for_pairwise_comparisons.R`.\nIt has NA values removed and the CIG points have been reduced to independent points only.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nval_dat <-  read_csv(\"data/validation_data_clusters_and_soil_props.csv\") %>% \n  mutate(proj_id = case_when(\n    str_detect(val_unit_id, \"CC$\") ~ \"NRCS-SHI\",\n    str_detect(val_unit_id, \"[:digit:]{3}$\") ~ \"KSSL\",\n    TRUE ~ \"CIG\"\n  ))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 146 Columns: 34\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): val_unit_id\ndbl (33): k_10, k_11, k_12, k_13, k_14, k_15, k_16, k_17, k_18, k_19, k_2, k...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# number of validation pts per project\nval_dat %>% \n  group_by(proj_id) %>% \n  count()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"proj_id\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"CIG\",\"2\":\"82\"},{\"1\":\"KSSL\",\"2\":\"29\"},{\"1\":\"NRCS-SHI\",\"2\":\"35\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# number of validation points overall\nnrow(val_dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 146\n```\n:::\n:::\n\n\nOK, so how many points do we have for each of the soil properties we are using to calculate cluster means?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nval_dat %>% \n  select(val_unit_id, claytotal, dbthirdbar, ph1to1h2o, caco3, om_loi) %>% \n  summarise(across(.cols = -val_unit_id,\n                   .fns = \\(xcol) sum(!is.na(xcol))))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"claytotal\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"dbthirdbar\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"ph1to1h2o\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"caco3\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"om_loi\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"144\",\"2\":\"131\",\"3\":\"144\",\"4\":\"98\",\"5\":\"125\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n",
    "supporting": [
      "19-sample-points_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}