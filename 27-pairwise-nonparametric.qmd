# (non-parametric) PCA Cluster pairwise comparisons

## Overview

Creating a page for non-parametric pairwise comparisons, because my assessment of the validation data is that we are violating the homogeneity of variance assumption, which we would normally require before doing ANOVA + Tukey's HSD to test differences between groups.

```{r setup}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(glue)
library(emmeans)
library(rstatix) # for kruskal_test and related stats 

clust_cols_to_character <- function(kcol){
  
  glue("clust_{kcol}")
  
}

# this dataset was created with script 
# 'prep_validation_data_for_pca_version.R'
val_dat <- read_csv("data/validation_data_pca_clusters_and_soil_props.csv") %>%
  # drop validation points not in target area
  # (will have value = clust_0 or clust_NA, I am
  # filtering on k_6 here but could use any of the k columns)
  filter(k_6 != "0",
         !is.na(k_6)) %>%
  mutate(across(contains("k_"), .fns = clust_cols_to_character),
         source = case_when(
           str_detect(val_unit_id, "-") ~ "CIG",
           str_detect(val_unit_id, "CC$") ~ "SHI",
           TRUE ~ "KSSL"
         )) %>% 
  # note: these are not in our AOI, but b/c I did the validation
  # for the PCA models based on MUKEY, had to filter them out 
  # here b/c there was no spatial component to the validation
  # (whereas the validation JB did w/ tifs for orig model
  # version did have a spatial component)
  filter(val_unit_id != "47CC", 
         val_unit_id != "47NCC")


# also want to load the input data (gSSURGO soil props
# associated w/ depth- and component-averaged MUKEYs)
mu_dat <- read_csv("data/mukey_cluster_assignments_and_soilprops.csv")

```

## Validation points per cluster

Here I am illustrating how many independent validation points we have for each cluster assignment, for the different model options from k = 4, 6, 8.

```{r}
#| echo: false

# make full cluster assignment df 
#  to make sure clusters with zero members 
# are still plotted (they are not included when we
# group by below)

make_clust_member_list <- function(k_val){
  
  num_rows <- k_val 
  
  data.frame(k = rep(glue("k_{k_val}"), num_rows),
             cluster_assignment = glue("clust_{1:num_rows}"))
  
}

clust_member_list <- map_dfr(.x = c(4, 5, 6, 7, 8, 9, 10, 11),
        .f = make_clust_member_list)

```

```{r}
#| echo: false

clust_counts <- val_dat %>%
  select(val_unit_id, contains("k_")) %>%
  pivot_longer(cols = contains("k_"),
               names_to = "k",
               values_to = "cluster_assignment") %>%
  group_by(k, cluster_assignment) %>%
  count() %>%
  right_join(x = .,
             y = clust_member_list,
             by = c("k", "cluster_assignment")) %>%
  mutate(
    # make sure clusters with zero members have n=0 so they appear on the plots
    # below
    n = replace_na(n, 0),
    # add leading zeros for nice sorting
    k = case_when(
      k == "k_4" ~ "k_04",
      k == "k_5" ~ "k_05",
      k == "k_6" ~ "k_06",
      k == "k_7" ~ "k_07",
      k == "k_8" ~ "k_08",
      k == "k_9" ~ "k_09",
      k == "k_10" ~ "k_10",
      k == "k_11" ~ "k_11",
      TRUE ~ k
    ),
    cluster_assignment = str_replace(cluster_assignment, "clust_", ""),
    cluster_assignment = case_when(
      cluster_assignment %in% as.character(c(1:9)) ~ glue("0{cluster_assignment}"), 
      TRUE ~ cluster_assignment
    ))
    
  

```

Note that clusters with only 1 member won't be included in pairwise comparison b/c not possible to calculate variance with only 1 member...

```{r}
#| echo: false


clust_counts %>% 
  ggplot() +
  geom_col(aes(x = cluster_assignment, y = n)) +
  geom_text(aes(x = cluster_assignment, y = n+3, label = n),
            color = "blue") +
  facet_wrap(vars(k), scales = "free") +
  theme_minimal() +
  ggtitle("Validation points") 



```

## Soil properties for pairwise comparisons

Because our validation data points are coming from different projects / datasets, we don't have exactly the same variables from each project.
This is a reminder of which variables exist in the three sources we used for validation points:

-   KSSL : clay, bulk density, lep, awc, ec, cec, pH, carbonates, organic matter, (est org C)
-   CIG: clay, bulk density, pH, carbonates, organic matter, (est org C)
-   SHI: clay, bulk density, pH, organic matter

In summary: all three datasets include bulk density, pH, organic matter, and clay, and KSSL and CIG include carbonates.
So I think it makes sense to focus on plotting and doing pairwise comparisons with these variables specifically

## Example pairwise: OM, k=6

Working out the steps I need to include in a function to do the pairwise comparisons.

```{r}

# test case k=6 version and organic matter

test_dat <- val_dat %>% 
  select(val_unit_id, k_6, om_loi, claytotal, source) %>% 
  drop_na(om_loi)

# note only 1 observation for clust_1, need to drop it
# b/c can't calculate variance for the pairwise comparison w/ only 1 obs.
test_dat %>% count(k_6)

test_dat_mult <- test_dat %>% filter(k_6 != "clust_1")

# plot to see distributions 
test_dat_mult %>% 
  ggplot(aes(x = k_6, y = om_loi)) + 
  geom_boxplot() + 
  geom_point() + 
  theme_bw()

test_lm <- lm(formula = om_loi ~ k_6,
   data = test_dat_mult)

# look at some diagnostic plots for our model 
# note homogeneity of variance looks sketchy
performance::check_model(test_lm, check = c("normality", "homogeneity", "linearity")) 

# runs Bartlett Test for homogeneity of variance
performance::check_homogeneity(test_lm) 

```

This shows how I would do a Kruskal-Wallis test followed by pairwise comparisons with Dunn's test, based on this blog post ["Kruskal-Wallis Test in R"](https://www.datanovia.com/en/lessons/kruskal-wallis-test-in-r/)

Note that the p-value adjustment method here is Holm, but there are other options (Bonferroni, Benjamani-Hochberg, etc.)

```{r}
test_dat_mult %>% 
  kruskal_test(om_loi ~ k_6)

# calculate eta-squared based on the H-statistic multiply by 100 for % variance
# in dependent variable (OM) explained by the independent variable (clusters)
test_dat_mult %>% 
  kruskal_effsize(om_loi ~ k_6)

# pairwise comps w/ Dunn's test 
test_pairs <- test_dat_mult %>%
  dunn_test(formula = as.formula("om_loi ~ k_6"), p.adjust.method = "holm") %>% 
# originally tried formatting the "comparison" column 
  # as in biostat::cld documentation, but the "=0" part
  # was messing up the cld labels. 
  mutate(comparison = glue("{group1}-{group2}"))


biostat::make_cld(p.adj ~ comparison, data = test_pairs)  
  

```

## Function to plot model checks

```{r}
# working with these variables for the model checks
# independent:  k= 4, 6, 8
# dependent:  vars = om_loi, dbthirdbar,  ph1to1h2o, caco3, claytotal

check_plots_anova <- function(soil_var, k_opt, df, log_trans_adj = FALSE) {
  
  dat_no_na <- df %>%
    select(val_unit_id,
           all_of(k_opt),
           all_of(soil_var)) %>%
    drop_na(all_of(soil_var))
  
  # checking if any clusters are represented by 1 or less data points. Want to drop these
  
  n_obs_per_cluster <- dat_no_na %>%
    count(.data[[k_opt]])
  
  single_obs_clusters <- n_obs_per_cluster %>%
    filter(n <= 1) %>%
    pull(.data[[k_opt]])
  
  if (length(single_obs_clusters) == 0) {
    dat_subset <- dat_no_na
    
  } else{
    dat_subset <- dat_no_na %>%
      filter(!(.data[[k_opt]] %in% single_obs_clusters))
    
  }
  
  if(log_trans_adj){
    
    # note this is for CaCO3, need to add 1 to avoid
    # zero values
    f <- paste0("log10(", soil_var, "+1)~", k_opt)
    
  }else{
    
    f <- paste0(soil_var, " ~ ", k_opt)
    
  }
  
  mod <- lm(formula = f,
            data = dat_subset)
  
  check_plots <- performance::check_model(mod, check = c("normality", "homogeneity", "linearity"))  
  
  return(list(var = glue("{soil_var}"),
              plots = check_plots))
  
}
```

## k=4 model checks

```{r}
check_plots_anova(soil_var = "claytotal",
                  k_opt = "k_4", 
                  df = val_dat)

check_plots_anova(soil_var = "ph1to1h2o",
                  k_opt = "k_4", 
                  df = val_dat)

check_plots_anova(soil_var = "dbthirdbar",
                  k_opt = "k_4", 
                  df = val_dat)

check_plots_anova(soil_var = "om_loi",
                  k_opt = "k_4", 
                  df = val_dat)

check_plots_anova(soil_var = "caco3",
                  k_opt = "k_4", 
                  df = val_dat,
                  log_trans_adj = TRUE)

```

## k=6 model checks

```{r}
check_plots_anova(soil_var = "claytotal",
                  k_opt = "k_6", 
                  df = val_dat)

check_plots_anova(soil_var = "ph1to1h2o",
                  k_opt = "k_6", 
                  df = val_dat)

check_plots_anova(soil_var = "dbthirdbar",
                  k_opt = "k_6", 
                  df = val_dat)

check_plots_anova(soil_var = "om_loi",
                  k_opt = "k_6", 
                  df = val_dat)

check_plots_anova(soil_var = "caco3",
                  k_opt = "k_6", 
                  df = val_dat,
                  log_trans_adj = TRUE)

```

## k=8 model checks

```{r}
check_plots_anova(soil_var = "claytotal",
                  k_opt = "k_8", 
                  df = val_dat)

check_plots_anova(soil_var = "ph1to1h2o",
                  k_opt = "k_8", 
                  df = val_dat)

check_plots_anova(soil_var = "dbthirdbar",
                  k_opt = "k_8", 
                  df = val_dat)

check_plots_anova(soil_var = "om_loi",
                  k_opt = "k_8", 
                  df = val_dat)

check_plots_anova(soil_var = "caco3",
                  k_opt = "k_8", 
                  df = val_dat, 
                  log_trans_adj = TRUE)

```

## Function for testing homogeneity of variance

Here I'm running the [Levene Test for Equality of Variances](https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm) as a way to check the homogeneity of variance assumption required for ANOVA.
If our k groups fail this test, would be better to do Kruskal-Wallis followed by Dunn's test for pairwise comparisons instead of ANOVA followed by Tukey's HSD.

```{r}

levene_test_clusts <- function(soil_var, k_opt, df) {
  
  ### prep data 
  
  dat_no_na <- df %>%
    select(val_unit_id,
           all_of(k_opt),
           all_of(soil_var)) %>%
    drop_na(all_of(soil_var)) 
  
  # can't do pairwise t-tests with only 1 obs in a
  # group (b/c need variance calc), so want to filter those out

  n_obs_per_cluster <- dat_no_na %>%
    count(.data[[k_opt]])

  single_obs_clusters <- n_obs_per_cluster %>%
    filter(n <= 1) %>%
    pull(.data[[k_opt]])

  if(length(single_obs_clusters) == 0){

    dat_subset <- dat_no_na

  }else{

    dat_subset <- dat_no_na %>%
      filter(!(.data[[k_opt]] %in% single_obs_clusters))

  }
  
  # gets rid of warning from levene_test about factor coercion
  dat_subset$k_opt_factor <- as.factor(dat_subset %>% pull(k_opt))
  
  ### perform levene test

  lev_df <- levene_test(data = dat_subset,
                        formula = as.formula(paste0(soil_var, " ~ ", "k_opt_factor")), center = median) %>% 
    mutate(var = soil_var, 
           k = k_opt)

  return(lev_df)

}


```

## Run Levene tests

```{r}
# example of what levene test function returns: 
levene_test_clusts(soil_var = "ph1to1h2o",
                       k_opt = "k_8",
                       df = val_dat)

# dependent vars
var_names <- c("claytotal", "ph1to1h2o", "om_loi", "caco3", "dbthirdbar")

# independent vars all possible values of k (number of clusters)
cluster_opts <- as.character(glue("k_{c(4, 5, 6, 7, 8, 9, 10, 11)}"))

# create df with all combinations of var_names x clusters
mod_template <- tidyr::crossing(var_names, cluster_opts)


ph <- map(.x = cluster_opts, 
    .f = ~levene_test_clusts(soil_var = "ph1to1h2o",
                             k_opt = .x, 
                             df = val_dat)) %>% 
  list_rbind()

clay <- map(.x = cluster_opts, 
    .f = ~levene_test_clusts(soil_var = "claytotal",
                             k_opt = .x, 
                             df = val_dat)) %>% 
  list_rbind()

om <- map(.x = cluster_opts, 
    .f = ~levene_test_clusts(soil_var = "om_loi",
                             k_opt = .x, 
                             df = val_dat)) %>% 
  list_rbind()

carbs <- map(.x = cluster_opts, 
    .f = ~levene_test_clusts(soil_var = "caco3",
                             k_opt = .x, 
                             df = val_dat)) %>% 
  list_rbind()

bd <- map(.x = cluster_opts, 
    .f = ~levene_test_clusts(soil_var = "dbthirdbar",
                             k_opt = .x, 
                             df = val_dat)) %>% 
  list_rbind()

lev_tests <- reduce(.x = list(ph, clay, om, carbs, bd),
                    .f = bind_rows)


```

## Check Levene Tests

Only bulk density passes the homogeneity of variance assumption, and it does so consistently for all values of k.

```{r}

lev_tests %>% 
  filter(p>0.05)

```

## Function for non-parametric pairwise comparisons

Arguments: soil property and k option (model version / number of clusters) and validation dataframe.

Returns: all pairwise comparisons in a dataframe

```{r}

compare_clust_pairwise <- function(soil_var, k_opt, df) {
  
  ### prep data 
  
  dat_no_na <- df %>%
    select(val_unit_id,
           all_of(k_opt),
           all_of(soil_var)) %>%
    drop_na(all_of(soil_var))
  
  # can't do pairwise t-tests with only 1 obs in a 
  # group, so need to filter those out 
  
  n_obs_per_cluster <- dat_no_na %>%
    count(.data[[k_opt]])
  
  single_obs_clusters <- n_obs_per_cluster %>% 
    filter(n <= 1) %>% 
    pull(.data[[k_opt]])
  
  if(length(single_obs_clusters) == 0){
    
    dat_subset <- dat_no_na
    
  }else{
    
    dat_subset <- dat_no_na %>% 
      filter(!(.data[[k_opt]] %in% single_obs_clusters))
    
  } 
  
  ### perform pairwise comparison
  
  pairs_df <- dunn_test(data = dat_subset,
                        formula = as.formula(paste0(soil_var, " ~ ", k_opt)), p.adjust.method = "holm") %>% 
    mutate(comparison = glue("{group1} - {group2}"))
  
  cld_df <- biostat::make_cld(p.adj ~ comparison, data = pairs_df)

  ### results
  
  results_list <- list(pairs_df = pairs_df,
                       cld = cld_df)

  return(results_list)
  
}


```

## Example function output

This is what the pairwise function I wrote above returns:

```{r}

ph_test <- compare_clust_pairwise(soil_var = "ph1to1h2o",
                       k_opt = "k_8",
                       df = val_dat) 

ph_test

comps <- ph_test[["pairs_df"]]

comps %>% 
  select(group1, group2, p.adj) %>% 
  filter(p.adj < 0.05) 

```

## Run pairwise comparisons

Here I create a dataframe to hold the results of the pairwise comparisons, then use `map2()` to iterate over the variables and cluster sizes, running all the tests.

```{r}

# run the pairwise comparisons for each var and cluster size
diffs_df <- mod_template %>%
  mutate(comps_all = map2(.x = var_names,
                          .y = cluster_opts,
                          .f = compare_clust_pairwise,
                          df = val_dat))

# unnest once to get the pairs_df and cld_df dfs 
# as their own columns
diffs_unnest <- diffs_df %>% 
  unnest(comps_all) %>% 
  mutate(obj_names = names(comps_all))

# want to save pairs_df and cld_df dat separately, so filtering
# and then unnesting again to get rectangular data 
pairs_dat <- diffs_unnest %>% 
  filter(obj_names == "pairs_df") %>% 
  unnest(comps_all) %>% 
  select(-obj_names)

write_csv(pairs_dat, "data/pca_nonpara_pairwise_results_all.csv")

cld_dat <- diffs_unnest %>% 
  filter(obj_names == "cld") %>% 
  unnest(comps_all) %>% 
  select(-obj_names)

write_csv(cld_dat, "data/cld_display_non_para.csv")


```

Now need to count how many of the tests have an adjusted p-value \< 0.05.
All of the p-values are already adjusted with the Holm method (you can see this in the function definition for `compare_clust_pairwise()` )

```{r}

count_sig_comps <- function(df){
  
  df %>% 
    filter(p.adj<0.05) %>% 
    nrow()
  
}

sig_diffs_df <- pairs_dat %>%
  select(cluster_opts, var_names, group1, group2, p.adj) %>% 
  group_by(cluster_opts, var_names) %>%
  nest(data = c(group1, group2, p.adj)) %>%
  mutate(n_sig_comps = map_int(data, count_sig_comps)) %>%
  mutate(
    num_regions = as.numeric(str_extract(cluster_opts, "[:digit:]+")),
    possible_comps = (num_regions * (num_regions - 1)) / 2,
    alpha_comps = round(possible_comps * 0.05, digits = 0)
  ) %>%
  select(var_names,
         cluster_opts,
         num_regions,
         data,
         n_sig_comps,
         possible_comps,
         alpha_comps)

sig_diffs_summary <- sig_diffs_df %>% 
  select(var_names,
         cluster_opts,
         num_regions,
         n_sig_comps,
         possible_comps,
         alpha_comps)

write_csv(sig_diffs_summary, "data/pca_nonpara_pairwise_comparisons_summary.csv")

```

## Plot comparisons

### All clusters

```{r}
#| echo: false

# plot n significant diffs vs. values of k
sig_diffs_summary %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_comps,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_comps,
                 color = var_names)) + 
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") + 
  ggtitle("Pairwise contrasts") +
  scale_x_continuous(breaks = c(4:11))


```

For context, this plot shows a black line for the total number of **possible** contrasts.
Note that because we are showing each soil property variable separately, the "total possible" line illustrates the total number of possible comparisons for a single variable

```{r}
#| echo: false

sig_diffs_summary %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_comps,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_comps,
                 color = var_names)) +
  geom_line(aes(x = num_regions, y = possible_comps, lty = "Tot. Possible (1 variable)")) +
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") + 
  ggtitle("Pairwise contrasts vs. total possible per variable") +
  scale_x_continuous(breaks = c(4:11)) +
  scale_linetype('') 

```

Two other ways to contextualize the number of significant contrasts: 1) with a table, and 2) with a plot showing how the % significant contrasts (as a function of total possible) changes as the number of clusters goes up.

```{r}
#| echo: false

comps_tbl <- sig_diffs_summary %>% 
  group_by(num_regions) %>% 
  summarise(across(.cols = c(n_sig_comps, possible_comps),
                   .fns = sum)) %>% 
  mutate(percent_sig = round((n_sig_comps/possible_comps)*100, digits = 0),
         alpha_5perc = round(possible_comps*0.05)) 

comps_tbl

comps_tbl %>% 
  ggplot() +
  geom_point(aes(x = num_regions, y = percent_sig),
             size = 3) + 
  geom_text(aes(x = num_regions, y = percent_sig+5, label = percent_sig),
            color = "red",
            size = 3) +
  scale_x_continuous(breaks = c(2:20)) +
  theme_minimal() +
  ylab("% significant contrasts") +
  xlab("Number of regions") +
  ggtitle("% significant contrasts out of total possible") 

```

```{r}
#| echo: false


sig_diffs_df %>% 
  mutate(perc_sig_indiv = (n_sig_comps / possible_comps)*100) %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = perc_sig_indiv,
                 group = var_names,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = perc_sig_indiv,
                 group = var_names,
                 color = var_names)) +
  theme_minimal() +
  scale_x_continuous(breaks = c(4:11)) +
  ggtitle("% sig contrasts by variable") +
  ylab("% significant contrasts") +
  xlab("Number of clusters/regions")

```
