# Cluster pairwise comparisons

## Overview

Now that I have the validation data extracted and combined with the soil property data, I can run pairwise comparisons between clusters for each value of k (different \# of clusters).
This may help us make an argument for why we chose one specific clustering (k=6 or k=8 for example) over others.

After processing all the validation data, we ended up with \~**140 points** to include (from CIG, NRCS-SHI, and NCSS-KSSL combined).
Devine et al. had 396 points.
The first thing I want to do is see how the points are distributed across the clusters (and perhaps also on a map of MN) to assess if this is sufficient.

I did identify a few sources for additional validation data, perhaps 20 additional points.
Nothing huge, but could add if we want to strengthen the case.
Notes in 2022-12-30 log entry about this.

```{r setup}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(glue)
library(emmeans)

clust_cols_to_character <- function(kcol){
  
  glue("clust_{kcol}")
  
}

# this dataset was created with script 
# 'prep_validation_data_for_pairwise_comparisons.R'
val_dat <- read_csv("data/validation_data_clusters_and_soil_props.csv") %>% 
  # drop validation points not in target area 
  # (will have value = 0 across all values of k, I am 
  # using k_2 here but could use any of the k columns)
  filter(k_2 != 0) %>% 
  mutate(across(contains("k_"), .fns = clust_cols_to_character),
         source = case_when(
           str_detect(val_unit_id, "-") ~ "CIG",
           str_detect(val_unit_id, "CC$") ~ "SHI",
           TRUE ~ "KSSL"
         ))

# also want to load the input data (gSSURGO soil props
# associated w/ depth- and component-averaged MUKEYs)
mu_dat <- read_csv("data/mukey_cluster_assignments_and_soilprops.csv")

```

## Validation points per cluster

Here I am illustrating how many independent validation points we have for each cluster assignment, for the different model options from k = 2 - 20.

```{r}
#| echo: false

# make full cluster assignment df 
#  to make sure clusters with zero members 
# are still plotted (they are not included when we
# group by below)

make_clust_member_list <- function(k_val){
  
  num_rows <- k_val 
  
  data.frame(k = rep(glue("k_{k_val}"), num_rows),
             cluster_assignment = glue("clust_{1:num_rows}"))
  
}

clust_member_list <- map_dfr(.x = c(2:20),
        .f = make_clust_member_list)

```

```{r}
#| echo: false

clust_counts <- val_dat %>%
  select(val_unit_id, contains("k_")) %>%
  pivot_longer(cols = contains("k_"),
               names_to = "k",
               values_to = "cluster_assignment") %>%
  group_by(k, cluster_assignment) %>%
  count() %>%
  right_join(x = .,
             y = clust_member_list,
             by = c("k", "cluster_assignment")) %>%
  mutate(
    # make sure clusters with zero members have n=0 so they appear on the plots
    # below
    n = replace_na(n, 0),
    # add leading zeros for nice sorting
    k = case_when(
      k == "k_2" ~ "k_02",
      k == "k_3" ~ "k_03",
      k == "k_4" ~ "k_04",
      k == "k_5" ~ "k_05",
      k == "k_6" ~ "k_06",
      k == "k_7" ~ "k_07",
      k == "k_8" ~ "k_08",
      k == "k_9" ~ "k_09",
      TRUE ~ k
    ),
    cluster_assignment = str_replace(cluster_assignment, "clust_", ""),
    cluster_assignment = case_when(
      cluster_assignment %in% as.character(c(1:9)) ~ glue("0{cluster_assignment}"), 
      TRUE ~ cluster_assignment
    ))
    
  

```

```{r}
#| echo: false


clust_counts %>% 
  filter(k %in% c("k_02", "k_03", "k_04", "k_05",
                  "k_06", "k_07")) %>% 
  ggplot() +
  geom_col(aes(x = cluster_assignment, y = n)) +
  facet_wrap(vars(k), scales = "free",
             ncol = 3) +
  theme_minimal() +
  ggtitle("Validation points per cluster (k = 2-7)") 

clust_counts %>% 
  filter(k %in% c("k_08", "k_09", "k_10", "k_11", "k_12", "k_13")) %>% 
  ggplot() +
  geom_col(aes(x = cluster_assignment, y = n)) +
  facet_wrap(vars(k), scales = "free",
             ncol = 3) +
  theme_minimal()+
  ggtitle("Validation points per cluster (k = 8-13)") 


clust_counts %>%
  filter(k %in% c("k_14", "k_15", "k_16", "k_17", "k_18", "k_19", "k_20")) %>%
  ggplot() +
  geom_col(aes(x = cluster_assignment, y = n)) +
  facet_wrap(vars(k), scales = "free",
             ncol = 2) +
  theme_minimal() +
  ggtitle("Validation points per cluster (k = 14-20)")

```

## Soil properties for pairwise comparisons

Because our validation data points are coming from different projects / datasets, we don't have exactly the same variables from each one.
This is a reminder of which variables exist in the three sources we used for validation points:

-   KSSL : clay, bulk density, lep, awc, ec, cec, pH, carbonates, organic matter, (est org C)
-   CIG: clay, bulk density, pH, carbonates, organic matter, (est org C)
-   SHI: clay, bulk density, pH, organic matter

In summary: all three datasets include bulk density, pH, organic matter, and clay, and KSSL and CIG include carbonates.
So I think it makes sense to focus on plotting and doing pairwise comparisons with these variables specifically

## Example pairwise: OM, k=6

Working out the steps I need to include in a function to do the pairwise comparisons.
This first chunk shows how I would do it if using one-way ANOVA followed by

```{r}

# test case k=6 version and organic matter

test_dat <- val_dat %>% 
  select(val_unit_id, k_6, om_loi, claytotal, source) %>% 
  drop_na(om_loi)

# plot to see distributions 
test_dat %>% 
  ggplot(aes(x = k_6, y = om_loi)) + 
  geom_boxplot() + 
  geom_point() + 
  theme_bw()

test_lm <- lm(formula = om_loi ~ k_6,
   data = test_dat)

# look at some diagnostic plots for our model 
# note homogeneity of variance looks sketchy
performance::check_model(test_lm, check = c("normality", "homogeneity", "linearity"))


```

This shows how I would do pairwise t-tests with unpooled variance.
This might be more appropriate than the ANOVA approach I originally tried, because the diagnostic plots above suggest that we don't have homogeneity of variance for our validation dataset.

*"For some examples, one can use both the pooled t-procedure and the separate variances (non-pooled) t-procedure and obtain results that are close to each other. However, when the sample standard deviations are very different from each other, and the sample sizes are different, the separate variances 2-sample t-procedure is more reliable." Penn State [STAT 800 "Applied Research Methods"](https://online.stat.psu.edu/stat800/lesson/5/5.6/5.6.1/5.6.1.2) 5.6.1.2*

Note that the p-value adjustment method here is "holm".

```{r}

# view the standard (console) output
with(test_dat, pairwise.t.test(om_loi, k_6, pool.sd = FALSE)) 

# tidy output, filter to significant comparisons only
with(test_dat, pairwise.t.test(om_loi, k_6, pool.sd = FALSE)) %>% broom::tidy() %>% 
  filter(p.value < 0.05)

```

## Function for pairwise comparisons

Arguments: soil property and k option (model version / number of clusters) and validation dataframe.

Returns: all pairwise comparisons in a dataframe

```{r}

compare_clust_pairwise <- function(soil_var, k_opt, df) {
  
  dat_no_na <- df %>%
    select(val_unit_id,
           all_of(k_opt),
           all_of(soil_var)) %>%
    drop_na(all_of(soil_var))
  
  # can't do pairwise t-tests with only 1 obs in a 
  # group, so need to filter those out 
  
  n_obs_per_cluster <- dat_no_na %>%
    count(.data[[k_opt]])
  
  single_obs_clusters <- n_obs_per_cluster %>% 
    filter(n == 1) %>% 
    pull(.data[[k_opt]])
  
  if(length(single_obs_clusters) == 0){
    
    dat_subset <- dat_no_na
    
  }else{
    
    dat_subset <- dat_no_na %>% 
      filter(!(.data[[k_opt]] %in% single_obs_clusters))
    
  } 
  
  soil_var_vec <- dat_subset %>% pull(soil_var)
  clust_vec <- dat_subset %>% pull(k_opt)

  pairs_df <- pairwise.t.test(soil_var_vec,
                              clust_vec,
                              pool.sd = FALSE) %>%
    broom::tidy()

  return(pairs_df)
  
}

quiet_compare_clust_pairwise <- purrr::quietly(.f = compare_clust_pairwise)


```

## Example function output

This is what the pairwise function returns:

```{r}

compare_clust_pairwise(soil_var = "ph1to1h2o",
                       k_opt = "k_10",
                       df = val_dat) 

```

## Run pairwise comparisons

Here I create a dataframe to hold the results of the pairwise comparisons, then use `map2()` to iterate over the variables and cluster sizes, running all the tests.

```{r}
# vars to compare on 
var_names <- c("claytotal", "ph1to1h2o", "om_loi", "caco3", "dbthirdbar")

# all possible values of k (number of clusters)
cluster_opts <- glue("k_{2:20}")

# create df with all combinations of var_names x clusters
comp_template <- tidyr::crossing(var_names, cluster_opts)

# run the pairwise comparisons for each var and cluster size
diffs_df <- comp_template %>%
  mutate(comps_all = map2(.x = var_names,
                          .y = cluster_opts,
                          .f = compare_clust_pairwise,
                          df = val_dat))


```

Now need to count how many of the tests have an adjusted p-value \< 0.05.
All of the p-values are adjusted with the Tukey method.

```{r}

count_sig_comps <- function(df){
  
  df %>% 
    filter(p.value<0.05) %>% 
    nrow()
  
}

sig_diffs_df <- diffs_df %>%
  mutate(n_sig_pair_diffs = map_int(comps_all, count_sig_comps)) %>% select(-comps_all) %>%
  mutate(num_regions = as.numeric(str_extract(cluster_opts, "[:digit:]+")),
         possible_comps = (num_regions * (num_regions - 1)) / 2)

write_csv(sig_diffs_df, file = "data/original_pairwise_comparisons.csv")

```

## Plot comparisons

### All clusters

First we can look at a plot of all the cluster sizes, from 2-20.
For carbonates, bulk density, and organic matter, this plot seems to level off around k=11.
For clay and pH, we continue to see an increase in the number of significant contrasts beyond k=11.
This pattern is more apparent when looking at the smoothed trends in the second plot here.

```{r}
#| echo: false

# plot n significant diffs vs. values of k
sig_diffs_df %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) + 
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") + 
  ggtitle("Pairwise contrasts, all models (2-20)") +
  scale_x_continuous(breaks = c(2:20))

# smoothed trends
sig_diffs_df %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_smooth(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names), 
              se = FALSE) + 
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") + 
  ggtitle("Smoothed trends, all models (2-20)") +
  scale_x_continuous(breaks = c(2:20))


```

For context, this plot shows a black line for the total number of **possible** contrasts

```{r}
#| echo: false

sig_diffs_df %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_line(aes(x = num_regions, y = possible_comps, lty = "Tot. Possible Contrasts")) +
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") + 
  ggtitle("Pairwise contrasts vs. total possible, all models (2-20)") +
  scale_x_continuous(breaks = c(2:20)) +
  scale_linetype('') 

```

Two other ways to contextualize the number of significant contrasts: 1) with a table, and 2) with a plot showing how the % significant contrasts (as a function of total possible) changes as the number of clusters goes up.

For the % significant contrasts, we see local maxima at k = 8 and k = 11, although the one at k = 11 is slightly smaller.

```{r}
#| echo: false

comps_tbl <- sig_diffs_df %>% 
  group_by(num_regions) %>% 
  summarise(across(.cols = c(n_sig_pair_diffs, possible_comps),
                   .fns = sum)) %>% 
  rename(sig_comps = n_sig_pair_diffs) %>% 
  mutate(percent_sig = round((sig_comps/possible_comps)*100, digits = 0),
         alpha_5perc = round(possible_comps*0.05)) 

comps_tbl

comps_tbl %>% 
  ggplot() +
  geom_line(aes(x = num_regions, y = percent_sig)) + 
  geom_text(aes(x = num_regions, y = percent_sig+5, label = percent_sig),
            color = "red",
            size = 3) +
  scale_x_continuous(breaks = c(2:20)) +
  theme_minimal() +
  ylab("% significant contrasts") +
  xlab("Number of regions") +
  ggtitle("% significant contrasts out of total possible") 

```

### k = 5-15

Let's look more closely at our model options in the middle range, from 5-15.

```{r}
#| echo: false


sig_diffs_df %>% 
  filter(num_regions %in% c(5:15)) %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) + 
  geom_line(aes(x = num_regions, y = possible_comps, lty = "Possible contrasts")) +
  scale_x_continuous(breaks = c(5:15)) + 
  scale_linetype('') +
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") +
  ggtitle("Pairwise comparisons for 5-15 clusters")


```

Dropping the "total possible" line makes marginal changes from one model to another easier to see (below).
What I notice about the graph below:

-   Increase in number of significant contrasts from k=7 to k=8, driven by clay, ph, bulk density
-   No sig contrasts added from k=8 to k=9, and only a couple added from bulk density from k=9 to k=10
-   From k=10 to k=11. we add significant contrasts in pH, bulk density, organic matter, and clay
-   from k=11 to k=12, big jump in contrasts driven by pH

```{r}
#| echo: false

sig_diffs_df %>% 
  filter(num_regions %in% c(5:15)) %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = n_sig_pair_diffs,
                 color = var_names)) + 
  scale_x_continuous(breaks = c(5:15)) + 
  scale_linetype('') +
  theme_minimal() +
  xlab("Number of Clusters/Regions") +
  ylab("Sig. pairwise contrasts (validation)") +
  ggtitle("Pairwise comparisons for 5-15 clusters")

sig_diffs_df %>% 
  filter(num_regions %in% c(5:15)) %>% 
  mutate(perc_sig_indiv = (n_sig_pair_diffs / possible_comps)*100) %>% 
  ggplot() +
  geom_point(aes(x = num_regions,
                 y = perc_sig_indiv,
                 group = var_names,
                 color = var_names)) +
  geom_line(aes(x = num_regions,
                 y = perc_sig_indiv,
                 group = var_names,
                 color = var_names)) +
  theme_minimal() +
  scale_x_continuous(breaks = c(5:15)) +
  ggtitle("% sig contrasts by variable") +
  ylab("% significant contrasts") +
  xlab("Number of clusters/regions")

```

### Clay and OM contrasts for k = 7-12

From the plots above, we've learned that differences in clay and organic matter are primarily responsible for the significant contrasts we see being added from the k=7 model up to the k=12 model.
In particular, we know that the move from the k=10 model to k=11 model results in an increased % of significant contrasts in these two variables (see immediately preceding plot)

The table below illustrates the number of significant contrasts for each model version in the k=7-12 range, for clay and organic matter.
Note that there are 10 significant contrasts added for clay when going from k=10 to k=11.

I was curious to know why this was, so I looked at some of the alluvial plots in `_refs`.
The dimensions of these make it hard to display them legibly in HTML format, but looking at `alluvial_k8-11.pdf` , I can see that the new cluster added in k_11 is a relatively small (n=200 mapunits) group of the highest clay soils which also have EC \~1 and 3% carbonates.
This is also illustrated in the k=11 map grids in the folllowing chapter.

```{r}
#| echo: false

diffs_long <- diffs_df %>% 
  select(var_names, cluster_opts, comps_all) %>% 
  unnest(comps_all)

om_clay_diffs_7_12 <- diffs_long %>% 
  select(var_names, cluster_opts, group1, group2, p.value) %>% 
  filter(p.value < 0.05, 
         var_names %in% c("om_loi", "claytotal"),
         cluster_opts %in% c("k_7", "k_8", "k_9", "k_10", "k_11", "k_12")) %>% 
  mutate(p.value = round(p.value, digits = 4))

om_clay_diffs_7_12 %>% 
  group_by(var_names, cluster_opts) %>% 
  count() %>% 
  arrange(var_names, cluster_opts) %>% 
  pivot_wider(names_from = "var_names",
              values_from = "n")

```
